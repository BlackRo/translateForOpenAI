# Vision 视觉

了解如何使用GPT-4来理解图像

## 介绍

GPT-4具备视觉功能，有时也被称为[GPT-4V](https://openai.com/research/gpt-4v-system-card)或API中的gpt-4-vision-preview，它使模型能够接收图像并回答与之相关的问题。历史上，语言模型系统受限于只接收文本这一输入模态。对于许多用例而言，这限制了类似GPT-4这样的模型的应用领域。

GPT-4具备视觉功能，目前所有通过gpt-4-vision-preview模型和更新支持图像输入的Chat Completions API的[开发人员](https://help.openai.com/en/articles/7102672-how-can-i-access-gpt-4)都可以使用。请注意，[Assistants API](https://platform.openai.com/docs/api-reference/assistants)目前不支持图像输入。

重要的是要注意以下几点：
- 具有视觉的 GPT-4 Turbo 的行为可能与 GPT-4 Turbo 略有不同，因为我们会自动将系统消息插入对话中
- 带视觉的 GPT-4 Turbo 与 GPT-4 Turbo 预览模型相同，在文本任务上表现同样出色，但增加了视觉功能
- Vision 只是该模型具有的众多功能之一

:::tip 提示
目前，GPT-4 Turbo with vision不支持message.name参数、函数/工具、response_format参数，并且我们目前设置了一个可以覆盖的低max_tokens默认值。
:::

## 快速开始

图像可通过两种主要方式提供给模型：通过传递到图像的链接或直接在请求中传递base64编码的图像。图像可以在user、system和assistant消息中传递。目前，我们不支持在第一个system消息中显示图像，但这可能会在未来发生变化。

<visionDemo/>

该模型最擅长回答有关图像中存在的内容的一般问题。虽然它确实理解了图像中对象之间的关系，但它还没有经过优化，无法回答有关图像中某些对象位置的详细问题。例如，你可以问它一辆车是什么颜色，或者根据冰箱里的东西，晚餐的一些想法可能是什么，但如果你给它看一张房间的图片，问它椅子在哪里，它可能不会正确回答这个问题。

在探索可视化理解可以应用于哪些用例时，请记住模型的[局限性](https://platform.openai.com/docs/guides/vision/limitations)，这一点很重要。

<videoVision/>

## 上传base64 encoded图像

如果您在本地有一个图像或一组图像，您可以将这些图像以base64编码的格式传递给模型，下面是一个示例：

<uploadBase64/>

## 多图像输入

 Chat Completions API 能够接收和处理以base64编码格式或作为图像URL的多个图像输入。该模型将处理每个图像，并使用来自所有图像的信息来回答问题。

<multipleImage/>

在这里，模型显示了同一图像的两个副本，并且可以独立地回答关于两个或每个图像的问题。

## 低保真度或高保真度图像理解


通过控制 detail 参数（有三个选项，low、high 或 auto），您可以控制模型如何处理图像并生成其文本理解。默认情况下，模型将使用 auto 设置，该设置将查看图像输入大小，并决定应使用low设置还是high 设置。


- low: 将禁用“high res 高分辨率”模型。该模型将收到低分辨率512px x 512px版本的图像，并以65个tokens的预算表示图像。这允许API为不需要高细节的用例返回更快的响应并消耗更少的输入tokens。

- high :开启"high res"模式将使模型首先查看低分辨率图像，然后根据输入图像的大小创建详细的512像素方形裁剪图像。每个详细的裁剪图像使用的tokens预算是原来的两倍（65个tokens），总共使用129个tokens。

<chooseDetail/>

## 管理图像

与Assistants API不同，Chat Completions API不具备状态保持功能。这意味着您必须自己管理传递给模型的消息（包括图像）。如果您想多次向模型传递相同的图像，则每次向API发出请求时都必须传递该图像。

对于长时间运行的对话，我们建议通过URL而不是base64传递图像。此外，通过预先调整图像大小，使其小于预期的最大尺寸，还可以改善模型的延迟。对于低分辨率模式，我们期望使用512像素 x 512像素的图像。对于高分辨率模式，图像的短边应小于768像素，长边应小于2000像素。

在模型处理完图像后，它将从OpenAI服务器中删除而不保留。[我们不使用通过OpenAI API上传的数据来训练我们的模型](https://openai.com/enterprise-privacy)。

## 局限性

虽然具备视觉功能的GPT-4在许多情况下非常强大且实用，但了解该模型的局限性也非常重要。以下是我们所了解到的一些局限性：

- 医学图像：该模型不适用于解读专业医学图像，如CT扫描，并且不应用于医疗建议。

- 非英语文本：该模型在处理非拉丁字母文字（如日文或韩文）的图像时可能表现不佳。

- 小文字：请将图像中的文本放大以提高可读性，但避免裁剪重要细节。

- 旋转：模型可能会误解旋转/倒置的文本或图像。

- 视觉元素：模型可能难以理解颜色或样式（如实线、虚线或点线）不同的图表或文本。

- 空间推理：模型在需要精确空间定位的任务中表现困难，例如识别棋局。

- 准确性：在某些情况下，模型可能会生成错误的描述或标题。

- 图像形状：模型在全景和鱼眼图像上表现困难。

- 元数据和调整大小：模型不处理原始文件名或元数据，并且在分析之前会调整图像的大小，从而影响其原始尺寸。

- 计数：模型可能会对图像中的对象给出近似计数。

- CAPTCHA：出于安全原因，我们已实施了一个系统来阻止提交CAPTCHA验证码。

## 成本估算

图像输入的计费方式与文本输入相同，按token计量并收费。给定图像的token成本由两个因素确定：其大小和每个image_url块上的详细选项。所有detail: low的图像每个花费85个token。detail: high的图像首先按照比例缩放以适应2048 x 2048的正方形内，然后按照最短边为768像素进行缩放。最后，我们计算图像由多少个512像素方形组成。每个方形的成本为170个token。最终总数始终会增加额外的85个token。

下面是一些例子来说明以上内容。

- 一个1024 x 1024正方形的图像细节：高模式需要765个token
    - 1024小于2048，因此没有初始大小调整。
    - 最短的边是1024，所以我们将图像缩小到768 x 768。
    - 需要4个512px的正方形切片来表示图像，因此最终的token成本为170*4+85=765。
- 2048 x 4096的详细图像：高模式成本为1105个token
    - 我们将图像缩小到1024 x 2048以适应2048平方。
    - 最短的边是1024，所以我们进一步缩小到768 x 1536。
    - 需要6个512px的切片，因此最终token成本为170*6+85=1105。
- 一个4096 x 8192的图像在detail: low模式下的成本为85个token
    - 无论输入大小如何，低详细图像的成本是固定的。

## FAQ

### 我可以微调gpt-4中的图像功能吗？

不，目前我们不支持对gpt-4的图像功能进行微调。

### 我可以使用gpt-4生成图像吗？

不，您可以使用dall-e-3生成图像，使用gpt-4-vision-preview来理解图像。

### 我可以上传什么类型的文件？

我们目前支持PNG（.PNG）、JPEG（.JPEG和.jpg）、WEBP（.web）和非动画GIF（.GIF）。

### 我可以上传的图片大小有限制吗？

是的，我们将图片上传限制为每张图片20MB。

### 我可以删除我上传的图片吗？

不，我们将在模型处理后自动为您删除图像。

### 我在哪里可以了解更多关于GPT-4与Vision的注意事项？

您可以在[GPT-4 with Vision](https://openai.com/contributions/gpt-4v)系统中找到有关我们评估、准备和缓解工作的详细信息。

为了安全起见，我们已经实施了一个系统来阻止提交CAPTCHA验证码。

### GPT-4 with Vision的速率限制是如何工作的？

我们在token级别处理图像，因此我们处理的每个图像都计入您的每分钟token（TPM）限制。有关用于确定每张图像的token计数的公式的详细信息，请参阅计算成本部分。

### 带Vision的GPT-4能否理解图像元数据？

否，该模型不接收图像元数据。

### 如果我的图像不清楚会发生什么？

如果图像不明确或不清晰，模型会尽最大努力对其进行解释。然而，结果可能不太准确。一个很好的经验法则是，如果普通人不能以低/高分辨率模式下使用的分辨率看到图像中的信息，那么模型也不能。

<script setup>
import visionDemo from './components/visionDemo.vue'
import videoVision from './components/videoVision.vue'
import uploadBase64 from './components/uploadBase64.vue'
import multipleImage from './components/multipleImage.vue'
import chooseDetail from './components/chooseDetail.vue'

</script>